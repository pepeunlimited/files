// Code generated by entc, DO NOT EDIT.

package ent

import (
	"context"
	"fmt"
	"time"

	"github.com/facebookincubator/ent/dialect/sql"
	"github.com/facebookincubator/ent/dialect/sql/sqlgraph"
	"github.com/facebookincubator/ent/schema/field"
	"github.com/pepeunlimited/files/internal/pkg/ent/bucket"
	"github.com/pepeunlimited/files/internal/pkg/ent/file"
	"github.com/pepeunlimited/files/internal/pkg/ent/predicate"
)

// BucketUpdate is the builder for updating Bucket entities.
type BucketUpdate struct {
	config
	name              *string
	endpoint          *string
	cdn_endpoint      *string
	clearcdn_endpoint bool
	created_at        *time.Time
	files             map[int]struct{}
	removedFiles      map[int]struct{}
	predicates        []predicate.Bucket
}

// Where adds a new predicate for the builder.
func (bu *BucketUpdate) Where(ps ...predicate.Bucket) *BucketUpdate {
	bu.predicates = append(bu.predicates, ps...)
	return bu
}

// SetName sets the name field.
func (bu *BucketUpdate) SetName(s string) *BucketUpdate {
	bu.name = &s
	return bu
}

// SetEndpoint sets the endpoint field.
func (bu *BucketUpdate) SetEndpoint(s string) *BucketUpdate {
	bu.endpoint = &s
	return bu
}

// SetCdnEndpoint sets the cdn_endpoint field.
func (bu *BucketUpdate) SetCdnEndpoint(s string) *BucketUpdate {
	bu.cdn_endpoint = &s
	return bu
}

// SetNillableCdnEndpoint sets the cdn_endpoint field if the given value is not nil.
func (bu *BucketUpdate) SetNillableCdnEndpoint(s *string) *BucketUpdate {
	if s != nil {
		bu.SetCdnEndpoint(*s)
	}
	return bu
}

// ClearCdnEndpoint clears the value of cdn_endpoint.
func (bu *BucketUpdate) ClearCdnEndpoint() *BucketUpdate {
	bu.cdn_endpoint = nil
	bu.clearcdn_endpoint = true
	return bu
}

// SetCreatedAt sets the created_at field.
func (bu *BucketUpdate) SetCreatedAt(t time.Time) *BucketUpdate {
	bu.created_at = &t
	return bu
}

// AddFileIDs adds the files edge to File by ids.
func (bu *BucketUpdate) AddFileIDs(ids ...int) *BucketUpdate {
	if bu.files == nil {
		bu.files = make(map[int]struct{})
	}
	for i := range ids {
		bu.files[ids[i]] = struct{}{}
	}
	return bu
}

// AddFiles adds the files edges to File.
func (bu *BucketUpdate) AddFiles(f ...*File) *BucketUpdate {
	ids := make([]int, len(f))
	for i := range f {
		ids[i] = f[i].ID
	}
	return bu.AddFileIDs(ids...)
}

// RemoveFileIDs removes the files edge to File by ids.
func (bu *BucketUpdate) RemoveFileIDs(ids ...int) *BucketUpdate {
	if bu.removedFiles == nil {
		bu.removedFiles = make(map[int]struct{})
	}
	for i := range ids {
		bu.removedFiles[ids[i]] = struct{}{}
	}
	return bu
}

// RemoveFiles removes files edges to File.
func (bu *BucketUpdate) RemoveFiles(f ...*File) *BucketUpdate {
	ids := make([]int, len(f))
	for i := range f {
		ids[i] = f[i].ID
	}
	return bu.RemoveFileIDs(ids...)
}

// Save executes the query and returns the number of rows/vertices matched by this operation.
func (bu *BucketUpdate) Save(ctx context.Context) (int, error) {
	if bu.name != nil {
		if err := bucket.NameValidator(*bu.name); err != nil {
			return 0, fmt.Errorf("ent: validator failed for field \"name\": %v", err)
		}
	}
	if bu.endpoint != nil {
		if err := bucket.EndpointValidator(*bu.endpoint); err != nil {
			return 0, fmt.Errorf("ent: validator failed for field \"endpoint\": %v", err)
		}
	}
	return bu.sqlSave(ctx)
}

// SaveX is like Save, but panics if an error occurs.
func (bu *BucketUpdate) SaveX(ctx context.Context) int {
	affected, err := bu.Save(ctx)
	if err != nil {
		panic(err)
	}
	return affected
}

// Exec executes the query.
func (bu *BucketUpdate) Exec(ctx context.Context) error {
	_, err := bu.Save(ctx)
	return err
}

// ExecX is like Exec, but panics if an error occurs.
func (bu *BucketUpdate) ExecX(ctx context.Context) {
	if err := bu.Exec(ctx); err != nil {
		panic(err)
	}
}

func (bu *BucketUpdate) sqlSave(ctx context.Context) (n int, err error) {
	_spec := &sqlgraph.UpdateSpec{
		Node: &sqlgraph.NodeSpec{
			Table:   bucket.Table,
			Columns: bucket.Columns,
			ID: &sqlgraph.FieldSpec{
				Type:   field.TypeInt,
				Column: bucket.FieldID,
			},
		},
	}
	if ps := bu.predicates; len(ps) > 0 {
		_spec.Predicate = func(selector *sql.Selector) {
			for i := range ps {
				ps[i](selector)
			}
		}
	}
	if value := bu.name; value != nil {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeString,
			Value:  *value,
			Column: bucket.FieldName,
		})
	}
	if value := bu.endpoint; value != nil {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeString,
			Value:  *value,
			Column: bucket.FieldEndpoint,
		})
	}
	if value := bu.cdn_endpoint; value != nil {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeString,
			Value:  *value,
			Column: bucket.FieldCdnEndpoint,
		})
	}
	if bu.clearcdn_endpoint {
		_spec.Fields.Clear = append(_spec.Fields.Clear, &sqlgraph.FieldSpec{
			Type:   field.TypeString,
			Column: bucket.FieldCdnEndpoint,
		})
	}
	if value := bu.created_at; value != nil {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeTime,
			Value:  *value,
			Column: bucket.FieldCreatedAt,
		})
	}
	if nodes := bu.removedFiles; len(nodes) > 0 {
		edge := &sqlgraph.EdgeSpec{
			Rel:     sqlgraph.O2M,
			Inverse: false,
			Table:   bucket.FilesTable,
			Columns: []string{bucket.FilesColumn},
			Bidi:    false,
			Target: &sqlgraph.EdgeTarget{
				IDSpec: &sqlgraph.FieldSpec{
					Type:   field.TypeInt,
					Column: file.FieldID,
				},
			},
		}
		for k, _ := range nodes {
			edge.Target.Nodes = append(edge.Target.Nodes, k)
		}
		_spec.Edges.Clear = append(_spec.Edges.Clear, edge)
	}
	if nodes := bu.files; len(nodes) > 0 {
		edge := &sqlgraph.EdgeSpec{
			Rel:     sqlgraph.O2M,
			Inverse: false,
			Table:   bucket.FilesTable,
			Columns: []string{bucket.FilesColumn},
			Bidi:    false,
			Target: &sqlgraph.EdgeTarget{
				IDSpec: &sqlgraph.FieldSpec{
					Type:   field.TypeInt,
					Column: file.FieldID,
				},
			},
		}
		for k, _ := range nodes {
			edge.Target.Nodes = append(edge.Target.Nodes, k)
		}
		_spec.Edges.Add = append(_spec.Edges.Add, edge)
	}
	if n, err = sqlgraph.UpdateNodes(ctx, bu.driver, _spec); err != nil {
		if cerr, ok := isSQLConstraintError(err); ok {
			err = cerr
		}
		return 0, err
	}
	return n, nil
}

// BucketUpdateOne is the builder for updating a single Bucket entity.
type BucketUpdateOne struct {
	config
	id                int
	name              *string
	endpoint          *string
	cdn_endpoint      *string
	clearcdn_endpoint bool
	created_at        *time.Time
	files             map[int]struct{}
	removedFiles      map[int]struct{}
}

// SetName sets the name field.
func (buo *BucketUpdateOne) SetName(s string) *BucketUpdateOne {
	buo.name = &s
	return buo
}

// SetEndpoint sets the endpoint field.
func (buo *BucketUpdateOne) SetEndpoint(s string) *BucketUpdateOne {
	buo.endpoint = &s
	return buo
}

// SetCdnEndpoint sets the cdn_endpoint field.
func (buo *BucketUpdateOne) SetCdnEndpoint(s string) *BucketUpdateOne {
	buo.cdn_endpoint = &s
	return buo
}

// SetNillableCdnEndpoint sets the cdn_endpoint field if the given value is not nil.
func (buo *BucketUpdateOne) SetNillableCdnEndpoint(s *string) *BucketUpdateOne {
	if s != nil {
		buo.SetCdnEndpoint(*s)
	}
	return buo
}

// ClearCdnEndpoint clears the value of cdn_endpoint.
func (buo *BucketUpdateOne) ClearCdnEndpoint() *BucketUpdateOne {
	buo.cdn_endpoint = nil
	buo.clearcdn_endpoint = true
	return buo
}

// SetCreatedAt sets the created_at field.
func (buo *BucketUpdateOne) SetCreatedAt(t time.Time) *BucketUpdateOne {
	buo.created_at = &t
	return buo
}

// AddFileIDs adds the files edge to File by ids.
func (buo *BucketUpdateOne) AddFileIDs(ids ...int) *BucketUpdateOne {
	if buo.files == nil {
		buo.files = make(map[int]struct{})
	}
	for i := range ids {
		buo.files[ids[i]] = struct{}{}
	}
	return buo
}

// AddFiles adds the files edges to File.
func (buo *BucketUpdateOne) AddFiles(f ...*File) *BucketUpdateOne {
	ids := make([]int, len(f))
	for i := range f {
		ids[i] = f[i].ID
	}
	return buo.AddFileIDs(ids...)
}

// RemoveFileIDs removes the files edge to File by ids.
func (buo *BucketUpdateOne) RemoveFileIDs(ids ...int) *BucketUpdateOne {
	if buo.removedFiles == nil {
		buo.removedFiles = make(map[int]struct{})
	}
	for i := range ids {
		buo.removedFiles[ids[i]] = struct{}{}
	}
	return buo
}

// RemoveFiles removes files edges to File.
func (buo *BucketUpdateOne) RemoveFiles(f ...*File) *BucketUpdateOne {
	ids := make([]int, len(f))
	for i := range f {
		ids[i] = f[i].ID
	}
	return buo.RemoveFileIDs(ids...)
}

// Save executes the query and returns the updated entity.
func (buo *BucketUpdateOne) Save(ctx context.Context) (*Bucket, error) {
	if buo.name != nil {
		if err := bucket.NameValidator(*buo.name); err != nil {
			return nil, fmt.Errorf("ent: validator failed for field \"name\": %v", err)
		}
	}
	if buo.endpoint != nil {
		if err := bucket.EndpointValidator(*buo.endpoint); err != nil {
			return nil, fmt.Errorf("ent: validator failed for field \"endpoint\": %v", err)
		}
	}
	return buo.sqlSave(ctx)
}

// SaveX is like Save, but panics if an error occurs.
func (buo *BucketUpdateOne) SaveX(ctx context.Context) *Bucket {
	b, err := buo.Save(ctx)
	if err != nil {
		panic(err)
	}
	return b
}

// Exec executes the query on the entity.
func (buo *BucketUpdateOne) Exec(ctx context.Context) error {
	_, err := buo.Save(ctx)
	return err
}

// ExecX is like Exec, but panics if an error occurs.
func (buo *BucketUpdateOne) ExecX(ctx context.Context) {
	if err := buo.Exec(ctx); err != nil {
		panic(err)
	}
}

func (buo *BucketUpdateOne) sqlSave(ctx context.Context) (b *Bucket, err error) {
	_spec := &sqlgraph.UpdateSpec{
		Node: &sqlgraph.NodeSpec{
			Table:   bucket.Table,
			Columns: bucket.Columns,
			ID: &sqlgraph.FieldSpec{
				Value:  buo.id,
				Type:   field.TypeInt,
				Column: bucket.FieldID,
			},
		},
	}
	if value := buo.name; value != nil {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeString,
			Value:  *value,
			Column: bucket.FieldName,
		})
	}
	if value := buo.endpoint; value != nil {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeString,
			Value:  *value,
			Column: bucket.FieldEndpoint,
		})
	}
	if value := buo.cdn_endpoint; value != nil {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeString,
			Value:  *value,
			Column: bucket.FieldCdnEndpoint,
		})
	}
	if buo.clearcdn_endpoint {
		_spec.Fields.Clear = append(_spec.Fields.Clear, &sqlgraph.FieldSpec{
			Type:   field.TypeString,
			Column: bucket.FieldCdnEndpoint,
		})
	}
	if value := buo.created_at; value != nil {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeTime,
			Value:  *value,
			Column: bucket.FieldCreatedAt,
		})
	}
	if nodes := buo.removedFiles; len(nodes) > 0 {
		edge := &sqlgraph.EdgeSpec{
			Rel:     sqlgraph.O2M,
			Inverse: false,
			Table:   bucket.FilesTable,
			Columns: []string{bucket.FilesColumn},
			Bidi:    false,
			Target: &sqlgraph.EdgeTarget{
				IDSpec: &sqlgraph.FieldSpec{
					Type:   field.TypeInt,
					Column: file.FieldID,
				},
			},
		}
		for k, _ := range nodes {
			edge.Target.Nodes = append(edge.Target.Nodes, k)
		}
		_spec.Edges.Clear = append(_spec.Edges.Clear, edge)
	}
	if nodes := buo.files; len(nodes) > 0 {
		edge := &sqlgraph.EdgeSpec{
			Rel:     sqlgraph.O2M,
			Inverse: false,
			Table:   bucket.FilesTable,
			Columns: []string{bucket.FilesColumn},
			Bidi:    false,
			Target: &sqlgraph.EdgeTarget{
				IDSpec: &sqlgraph.FieldSpec{
					Type:   field.TypeInt,
					Column: file.FieldID,
				},
			},
		}
		for k, _ := range nodes {
			edge.Target.Nodes = append(edge.Target.Nodes, k)
		}
		_spec.Edges.Add = append(_spec.Edges.Add, edge)
	}
	b = &Bucket{config: buo.config}
	_spec.Assign = b.assignValues
	_spec.ScanValues = b.scanValues()
	if err = sqlgraph.UpdateNode(ctx, buo.driver, _spec); err != nil {
		if cerr, ok := isSQLConstraintError(err); ok {
			err = cerr
		}
		return nil, err
	}
	return b, nil
}
